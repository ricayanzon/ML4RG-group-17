


import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import scipy as sp






# Load lncRNA-gene interactions
lnctard_df = pd.read_excel("data/lncRNA_Full_database.xlsx")



# Keep only rows where Regulator type is lncRNA
# the the node1 within this database is ALWAYS lncRNA

lnctard_df = lnctard_df[lnctard_df['RegulatorType'] == 'lncRNA']

# Rename and keep relevant columns
lnctard_df = lnctard_df.rename(columns={
     "Regulator": "node1",
     "Target": "node2",
     "regulatoryType": "interaction",
     "DiseaseName": "disease"
})

lnctard_df = lnctard_df.dropna(subset=["node1", "node2"])



# Remove all unnessasary columns from the database.
columns_to_keep = ['node1', 'node2', 'interaction', 'disease']
lnctard_df = lnctard_df[columns_to_keep]

lnctard_df["source"] = "lncRNA"

# Show first few rows after cleanup
print(lnctard_df.head())

# Save the filtered lnctard data in Exel file.
lnctard_df.to_excel("data/lnctard_Preprocessed_DB.xlsx", index=False)

print('lnctard_Preprocessed_DB was successfully created')

print("Row Numbers =", len(lnctard_df))





## can't upload string_Full_database.txt on github because it's large size.
## you can find the file here https://drive.google.com/file/d/14ye5c763D6BsZGKYVU_PtYoo-26Kl5VL/view?usp=sharing if you want to try it locally.
## will add the result file from this node (filtered_STRING_data.xlsx) directly in the data folder.


"""
# read the file with all database from STRING. it's really BIG more than 995 MB   
#df = pd.read_csv("/data/String_Full_database.txt", sep=" ")

# 13715404 rows in the original database
print("Row Numbers =", len(df))

# print the first 5 rows to see the structure.
print("The First five rows:")
print(df.head())

# print Columns names to get get familiar with the structure.
print("Columns Names:", df.columns.tolist())

# set a threshold to reduce the Noise and get more sutable data size(score ≥ 400)
filtered_df = df[df["combined_score"] >= 550]

# 891390 in the filtered database.
print("Numbers of rows after Filtering", len(filtered_df))

# Save the filtered data in Exel file.
filtered_df.to_excel("/data/filtered_STRING_data.xlsx", index=False)

print("the file filtered_STRING_data.xlsx saved successfully")
"""




# Show first few rows filtered_STRING_data.xlsx
#filtered_df.head()






df = pd.read_excel("data/filtered_STRING_data.xlsx")

# Get unique values from both columns
unique_col1 = set(df['protein1'].dropna().unique())
unique_col2 = set(df['protein2'].dropna().unique())

# Combine and sort the unique values
all_unique_values = sorted(unique_col1.union(unique_col2))

file_path = 'data/Unique_ENSP.txt'

# create empty txt file
with open(file_path, 'w') as f:
      pass

# Save the unique ENSP to text file
with open('data/Unique_ENSP.txt', 'w') as f:
      for value in all_unique_values:
          f.write(f"{value}\n")

print(f"Success! Found {len(all_unique_values)} unique values.")
print(f"Results saved to: {'data/Unique_ENSP.txt'}")




# Read txt file and print first few lines
with open('data/Unique_ENSP.txt', 'r') as f:
    for i in range(5):  # Read first 5 lines
        line = f.readline()
        print(line.strip())








uniprot_df = pd.read_excel("data/ENSP_to_geneName.xlsx")

# Show first few rows
uniprot_df.head()




# take the coloumns we need and drop the rest
uniprot_df = uniprot_df[["From", "Gene Names"]]

# take  nor the first gene name.
uniprot_df["Gene Symbol"] = uniprot_df["Gene Names"].str.split().str[0]

# prepare new file to use it in mapping ENSP ID → Gene Symbol
mapping_df = uniprot_df[["From", "Gene Symbol"]]


mapping_df.to_excel("data/ENSP_to_GeneSymbol_Cleaned.xlsx", index=False)

print("ENSP_to_GeneSymbol_Cleaned.xlsx was successfully created")



mapping_df.head()





interactions = pd.read_excel("data/filtered_STRING_data.xlsx")
mapping = pd.read_excel("data/ENSP_to_GeneSymbol_Cleaned.xlsx")

# first mapping protein1 → gene1
merged1 = interactions.merge(mapping, how="inner", left_on="protein1", right_on="From")
merged1 = merged1.rename(columns={"Gene Symbol": "gene1"}).drop("From", axis=1)

# now map protein2 → gene2 (use mapping file again)
merged_final = merged1.merge(mapping, how="inner", left_on="protein2", right_on="From")
merged_final = merged_final.rename(columns={"Gene Symbol": "gene2"}).drop("From", axis=1)

# keep only relevant columns
final_df = merged_final[["gene1", "gene2", "combined_score"]]

# save to Excel
final_df.to_excel("data/STRING_Preprocessed_DB.xlsx", index=False)

print("STRING_Preprocessed_DB.xlsx was successfully created")
final_df.head()


#number of rows of STRING DB after all preprocessing
print(len(final_df))





lnctard_df.head()


final_df.head()


final_df = final_df.rename(columns={
    "gene1": "node1",
    "gene2": "node2",
    "combined_score": "interaction"
})
final_df["source"] = "PPI"
final_df["disease"] = None

# merge two databases
merged_all = pd.concat([lnctard_df, final_df], ignore_index=True)

#remove rows with missing values at node1 or node2
clean_df = merged_all.dropna(subset=["node1", "node2"])


clean_df.to_excel("data/merged_lnctard_STring.xlsx", index=False)

print("merged preprocessed databases with total number of rows = ")
print(len(clean_df))



clean_df.head()





print('hi1')
clean_df = pd.read_excel("data/merged_lnctard_STring.xlsx")
print('hi2')
clean_df.head()
print('hi3')
#print('hi')


print(clean_df.head())


G = nx.Graph()

for _, row in clean_df.iterrows():
    G.add_node(row["node1"], type="lncRNA" if row["source"] == "lncRNA" else "protein") # node1 can be lncRNA or protein
    G.add_node(row["node2"], type="protein") # node2 always protien

    # add edge between node1 and node2 and add information (interaction and disease name) about relation
    G.add_edge(row["node1"], row["node2"], interaction=row["interaction"], disease=row["disease"])

# Graph metrics

print("Total nodes:", G.number_of_nodes())
print("Total edges:", G.number_of_edges())

# number of connected components
components = list(nx.connected_components(G))
print("Connected components:", len(components))

# number of nodes in the largest connected component.
print("Largest component size:", len(max(components, key=len)))

# average number of nodes which connected to each node
avg_deg = sum(dict(G.degree()).values()) / G.number_of_nodes()
print("Average degree:", round(avg_deg, 2))

# check graph Density
print("Density:", round(nx.density(G), 4))


print("\nTop 10 high-degree nodes:")

# top central nodes (degree)
top_nodes = sorted(G.degree(), key=lambda x: x[1], reverse=True)[:10]
for node, degree in top_nodes:
    print(f"{node}: {degree}")





# draw neighbors of a central hub node (TP53)

# Select a central hub node to visualize its neighborhood
central_node = "TP53"

# Get all nodes directly connected to the central node (its neighbors)
neighbors = list(G.neighbors(central_node))

# Include the central node itself
sub_nodes = [central_node] + neighbors

# Create the subgraph based on selected nodes
subgraph = G.subgraph(sub_nodes)

# Assign node colors based on type (lncRNA vs protein)
color_map = ['orange' if subgraph.nodes[n]['type'] == 'lncRNA' else 'skyblue' for n in subgraph.nodes]

# Draw the subgraph
plt.figure(figsize=(10, 8))
pos = nx.spring_layout(subgraph, seed=42)
nx.draw(
    subgraph, pos,
    with_labels=True,
    node_color=color_map,
    node_size=700,
    font_size=8,
    edge_color='gray'
)
plt.title("Subgraph around central node: {central_node}")
plt.show()



