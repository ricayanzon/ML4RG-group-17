{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.transforms import RandomLinkSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>interaction</th>\n",
       "      <th>disease</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINC00313</td>\n",
       "      <td>miR-4429</td>\n",
       "      <td>binding/interaction</td>\n",
       "      <td>Papillary thyroid carcinoma</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAM83H-AS1</td>\n",
       "      <td>CDKN1A</td>\n",
       "      <td>regulation</td>\n",
       "      <td>Malignant glioma</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEAT1</td>\n",
       "      <td>TGFB1</td>\n",
       "      <td>association</td>\n",
       "      <td>Hepatocellular carcinoma</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEAT1</td>\n",
       "      <td>ZEB1</td>\n",
       "      <td>regulation</td>\n",
       "      <td>Breast cancer</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZFPM2-AS1</td>\n",
       "      <td>MIF</td>\n",
       "      <td>binding/interaction</td>\n",
       "      <td>Gastric cancer</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node1     node2          interaction                      disease  \\\n",
       "0   LINC00313  miR-4429  binding/interaction  Papillary thyroid carcinoma   \n",
       "1  FAM83H-AS1    CDKN1A           regulation             Malignant glioma   \n",
       "2       NEAT1     TGFB1          association     Hepatocellular carcinoma   \n",
       "3       NEAT1      ZEB1           regulation                Breast cancer   \n",
       "4   ZFPM2-AS1       MIF  binding/interaction               Gastric cancer   \n",
       "\n",
       "   source  \n",
       "0  lncRNA  \n",
       "1  lncRNA  \n",
       "2  lncRNA  \n",
       "3  lncRNA  \n",
       "4  lncRNA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your merged dataframe\n",
    "df = pd.read_excel(\"data/merged_lnctard_STring.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahd\\AppData\\Local\\Temp\\ipykernel_20836\\2925118401.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  edge_index = torch.tensor([source, target], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features shape: torch.Size([20232, 2])\n",
      "Train edges: 610064\n",
      "Validation edges: 610064\n",
      "Test edges: 697214\n",
      "Node features shape: torch.Size([20232, 2])\n"
     ]
    }
   ],
   "source": [
    "# Extract edges\n",
    "edges = df[['node1', 'node2']]\n",
    "\n",
    "# Build full list of unique nodes\n",
    "all_nodes = pd.concat([edges['node1'], edges['node2']]).unique()\n",
    "\n",
    "# Apply label encoding to all nodes (convert gene names to integer IDs)\n",
    "le = LabelEncoder()\n",
    "le.fit(all_nodes)\n",
    "\n",
    "# Map node1 and node2 to encoded integers\n",
    "source = le.transform(edges['node1'])\n",
    "target = le.transform(edges['node2'])\n",
    "\n",
    "# Build edge_index tensor for PyG\n",
    "edge_index = torch.tensor([source, target], dtype=torch.long)\n",
    "num_nodes = len(le.classes_)\n",
    "\n",
    "# --------------------------------\n",
    "# Build Degree Feature (Feature 1)\n",
    "# --------------------------------\n",
    "node_degrees = np.zeros(num_nodes)\n",
    "for s, t in zip(source, target):\n",
    "    node_degrees[s] += 1\n",
    "    node_degrees[t] += 1\n",
    "\n",
    "degree_feature = node_degrees.reshape(-1, 1)\n",
    "\n",
    "# ------------------------------------\n",
    "# Build Node Type Feature (Feature 2)\n",
    "# ------------------------------------\n",
    "\n",
    "# Build dictionary of {node: type} from 'source' column in the file\n",
    "# 'source' column has the type info: 'lncRNA' or 'protein'\n",
    "node_type_dict = dict(zip(df['node1'], df['source']))\n",
    "\n",
    "# Build type feature for all encoded nodes\n",
    "node_types = []\n",
    "for gene in le.classes_:\n",
    "    type_str = node_type_dict.get(gene, \"PPI\")  # default to protein if not found\n",
    "    if type_str == 'lncRNA':\n",
    "        node_types.append(1)\n",
    "    else:\n",
    "        node_types.append(0)\n",
    "\n",
    "node_types = np.array(node_types).reshape(-1, 1)\n",
    "\n",
    "# ----------------------\n",
    "# Combine both features\n",
    "# ----------------------\n",
    "x = np.concatenate([degree_feature, node_types], axis=1)\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "# --------------------------\n",
    "# Build the PyG Data object\n",
    "# --------------------------\n",
    "data = Data(edge_index=edge_index, x=x, num_nodes=num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "# Apply random link split for train/val/test\n",
    "transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# Sanity check\n",
    "print(\"Node features shape:\", train_data.x.shape)\n",
    "# Check basic info\n",
    "print(f\"Train edges: {train_data.edge_index.shape[1]}\")\n",
    "print(f\"Validation edges: {val_data.edge_index.shape[1]}\")\n",
    "print(f\"Test edges: {test_data.edge_index.shape[1]}\")\n",
    "print(f\"Node features shape: {train_data.x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    \n",
    "    # in_channels should contains the number of node features\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        \n",
    "        ## the first two layers\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        ## output layer for link prediction which gives a final score for each edge\n",
    "        self.lin = torch.nn.Linear(hidden_channels, 1) \n",
    "\n",
    "        \n",
    "    # return node embedding for each node.\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)   ## RELU activation\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    # return probability of edge existance between each node pair\n",
    "    def decode(self, z, edge_label_index):\n",
    "        src = z[edge_label_index[0]]\n",
    "        dst = z[edge_label_index[1]]\n",
    "        return torch.sum(src * dst, dim=-1)  # dot product similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = train_data.edge_index\n",
    "val_edge_index = val_data.edge_index\n",
    "test_edge_index = test_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Assignment + Model Initialization + Preparation\n",
    "\n",
    "# select device to train on: use GPU if available else use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# intialize graphSAGE model\n",
    "model = GraphSAGE(in_channels=x.shape[1], hidden_channels=64).to(device)\n",
    "\n",
    "#Move node feature tensor to the same device as model (GPU or CPU)\n",
    "x = x.to(device)\n",
    "## same with edge features\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "\n",
    "\n",
    "#choose optimizer to update weights after each backpropagation step\n",
    "#Adam works excellent with most GNN.\n",
    "# learning rate =0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loop / The Core Learning Block\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # reset\n",
    "    z = model.encode(x, train_edge_index)  ## calculate node embeddings\n",
    "    pos_out = model.decode(z, train_edge_index) ## calculate probability for real edges in training data  \n",
    "    pos_label = torch.ones(pos_out.size(0), device=device) ## give 1 to positive samples \n",
    "\n",
    "\n",
    "    ## create random edges between random nodes to create negative samples\n",
    "    neg_edge_index = torch.randint(0, num_nodes, train_edge_index.size(), device=device)\n",
    "    neg_out = model.decode(z, neg_edge_index) ## calculate probability for UNreal edges in training data \n",
    "    neg_label = torch.zeros(neg_out.size(0), device=device)  # ## give 0 to negative samples\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out]) ## combine all predictions \n",
    "    labels = torch.cat([pos_label, neg_label]) ## combine all labels 0 or 1\n",
    "\n",
    "    # calculte loss function\n",
    "    loss = F.binary_cross_entropy_with_logits(out, labels)\n",
    "    loss.backward()   ##calculate gradients in backpropagation\n",
    "    optimizer.step()   ## update weights \n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 53359.0508\n",
      "Epoch 10, Loss: 20182.1211\n",
      "Epoch 15, Loss: 9519.5742\n",
      "Epoch 20, Loss: 5461.8022\n",
      "Epoch 25, Loss: 3390.5728\n",
      "Epoch 30, Loss: 2547.5698\n",
      "Epoch 35, Loss: 1434.9706\n",
      "Epoch 40, Loss: 1044.2664\n",
      "Epoch 45, Loss: 758.6997\n",
      "Epoch 50, Loss: 470.5381\n"
     ]
    }
   ],
   "source": [
    "# 50 cycle training\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Model Evaluation Block\n",
    "## link prediction evaluation with AUC Metric\n",
    "\n",
    "@torch.no_grad()   ## don't need gradients for this function, good for memory and speed.\n",
    "\n",
    "def test(edge_index):\n",
    "    model.eval()  # put model in evaluation mode.\n",
    "    z = model.encode(x, train_edge_index)  # caculate embeddings for training graph structure.\n",
    "    \n",
    "    #positive sampling \n",
    "    pos_out = model.decode(z, edge_index)  \n",
    "    pos_label = torch.ones(pos_out.size(0), device=device)\n",
    "\n",
    "    # negative sampling\n",
    "    neg_edge_index = torch.randint(0, num_nodes, edge_index.size(), device=device)\n",
    "    neg_out = model.decode(z, neg_edge_index)\n",
    "    neg_label = torch.zeros(neg_out.size(0), device=device)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out]).cpu()\n",
    "    labels = torch.cat([pos_label, neg_label]).cpu()\n",
    "\n",
    "    auc = roc_auc_score(labels, out)   ## calculate area under ROC curve / AUC score is very good for link predictions tasks.\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.8037\n",
      "Test AUC: 0.8038\n"
     ]
    }
   ],
   "source": [
    "val_auc = test(val_edge_index.to(device))\n",
    "test_auc = test(test_edge_index.to(device))\n",
    "\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN Env)",
   "language": "python",
   "name": "gnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
